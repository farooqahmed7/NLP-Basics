{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACY.\n",
    "-  Spacy is Open Source NLP Library, designed to effectively handle NLP tasks with the most efficient implementation of common algorithms.\n",
    "-  It has one implemented method i.e choosing the most efficient algorithm currently available.\n",
    "\n",
    "# NLTK.\n",
    "-  NLTK is **Natural Language tool kit**, very popular open source. It provides much functionalities but includes less efficient implementations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. conda install -c conda-forge spacy\n",
    "# 2. python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP.\n",
    " - Natural Language Processing is an area of computer science and artificial intelligence concerned with the interactions between computers and human(natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
    " - To process the text data, computer needs specialized processing techniques in order to **understand** raw text data.\n",
    " - Text data is highly unstructured and can be in multiple languages.\n",
    "\n",
    "### Examples\n",
    "- Classifying emails as Spam vs Legitimate\n",
    "- Sentiment Analysis of Text Movie Review\n",
    "- Analysing Trends from written customer feedback\n",
    "- Understanding text commands, \"Hey Google, play this song\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spacy Basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific string en_core i.e core english language and web_sm i.e small version of this library\n",
    "# This is loading a model.\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Document object by appling our model to our text.\n",
    "doc = nlp(u'Tesla in looking at buying U.S starup for $6 million')\n",
    "# Using language library developed, it parse this string in seperate components for us. It parse as tokens.\n",
    "# Each word becomes as token.\n",
    "# 'u' is unique quote string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "in\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.S\n",
      "starup\n",
      "for\n",
      "$\n",
      "6\n",
      "million\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 84\n",
      "in 85\n",
      "looking 100\n",
      "at 85\n",
      "buying 100\n",
      "U.S 96\n",
      "starup 92\n",
      "for 85\n",
      "$ 99\n",
      "6 93\n",
      "million 93\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos)\n",
    "# Below each umber corresponds to parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla ADJ\n",
      "in ADP\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.S PROPN\n",
      "starup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "6 NUM\n",
      "million NUM\n"
     ]
    }
   ],
   "source": [
    "# To get particular parts of speech,\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla ADJ ROOT\n",
      "in ADP prep\n",
      "looking VERB pcomp\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S PROPN compound\n",
      "starup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# for more info, we can use _dep which stands for Syntactic Dependency.\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x16ea5c322e8>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x16ea5c226a8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x16ea5c22708>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline\n",
    "# Basic nlp pipeline has tagger, parser and ner i.e name entity recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't   looking into startups anymore.\")\n",
    "# Even space becomes token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "   SPACE \n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "n't\n"
     ]
    }
   ],
   "source": [
    "# To print individual tokens.\n",
    "print(doc2[0])\n",
    "print(doc2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUX\n"
     ]
    }
   ],
   "source": [
    "print(doc2[1].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT\n"
     ]
    }
   ],
   "source": [
    "# syntactic dependency\n",
    "print(doc2[4].dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xx'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The word shape – capitalization, punctuation, digits\t\n",
    "doc2[1].shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The base form of the word.\n",
    "doc2[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spans\n",
    " - A Span is a slice of Doc object in the form of start vs stop.\n",
    " - doc[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Span\n",
    "life_quote = doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentence. This is second sentence. This is the last sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is second sentence.\n",
      "This is the last sentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence) \n",
    "# sents is an attribute to print each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check whether this is starting of sentence.\n",
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is second sentence. This is the last sentence"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[7].is_sent_start\n",
    "# It doesnt return anything since its not a start of sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Tokenization.\n",
    " - The process of breaking up original text into component pieces(tokens.\n",
    " - Tokens are the building blocks of a Doc object, i.e everything that helps us  to understand the meaning of the text is derived from tokens and their relationship to one another.\n",
    " - Prefix: Character(s) at the beginning. eg- $, @ etc\n",
    " - Suffix: Character(s) at the end. eg- km, rs etc\n",
    " - Infix: character(s) in between. eg- ...., -----, etc\n",
    " - Excetion: Special-case use to split a string into several tokens or prevent a token from being split when punctuation rules are applied. eg- let's U.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load spacy library\n",
    "nlp =spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = '\"we\\'re moving to L.A !\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"we're moving to L.A !\"\n"
     ]
    }
   ],
   "source": [
    "print(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "we\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"A 5km NYC cab ride costs $10.30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exceptions\n",
    "- Punctuations that exists as part of a known abbreviation will be kept as part of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the number of tokens in document.\n",
    "len(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x16ea5f5dea0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the Vocab Entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc4.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"It is better to give than receive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the doc using index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better to give"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[2:5]\n",
    "# tokens cant be reassigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities.\n",
    "-  The language model recognizes that certain words are organizational names while others are locations and still some other combinations relate to money, dates, etc\n",
    "- this can be accessable through ents property of a doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8 = nlp(u\"Apple to build a Hong Kong factory for $6 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | "
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Hong Kong\n",
      "$6 million\n"
     ]
    }
   ],
   "source": [
    "# Using ents property\n",
    "for entity in doc8.ents:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "Hong Kong\n",
      "GPE\n",
      "Countries, cities, states\n",
      "\n",
      "\n",
      "$6 million\n",
      "MONEY\n",
      "Monetary values, including unit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    print(str(spacy.explain(entity.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Chunks.\n",
    "- This is another object property. these are \"base noun phrases\" i.e flat phrases that have a noun as their head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability towards manufactures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufactures\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info on noun_chunks visit https://spacy.io/usage/linguistic-features#noun-chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apple is going to build a U.K. factory for $6 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f906ead4d6aa4059883e362924ad161c-0\" class=\"displacy\" width=\"1130\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">million</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,92.0 220.0,92.0 220.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-2\" stroke-width=\"2px\" d=\"M340,182.0 C340,137.0 395.0,137.0 395.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,92.0 400.0,92.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-6\" stroke-width=\"2px\" d=\"M430,182.0 C430,47.0 675.0,47.0 675.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,184.0 L683.0,172.0 667.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-7\" stroke-width=\"2px\" d=\"M430,182.0 C430,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,92.0 1030.0,92.0 1030.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-9\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f906ead4d6aa4059883e362924ad161c-0-10\" stroke-width=\"2px\" d=\"M790,182.0 C790,47.0 1035.0,47.0 1035.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f906ead4d6aa4059883e362924ad161c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1035.0,184.0 L1043.0,172.0 1027.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = 'dep', jupyter= True, options= {'distance':90})\n",
    "# distance inside options module is distance between each token.\n",
    "# jupyter is True, since we're using jupyter notebook\n",
    "# style is a one of the styles parameters. 'dep' is syntactic dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the entity recognizer.\n",
    "doc = nlp(u\"Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style= 'ent', jupyter = True,)\n",
    "# Style is 'ent' i.e entity\n",
    "# Here in this style format it identifies and highlights every entity "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To display on local host.\n",
    "doc = nlp(u\"This is a Sentence.\")\n",
    "displacy.serve(doc, style = 'dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stemming.\n",
    "- Stemming is method for cataloging related words, its essentially chops off letters from the end unitl the stem is reached.\n",
    "-  It works fairly in most cases, but unfortunately English has many exceptions where a more sophisticated process is required. Even SpaCy does'nt include a stemmer instead rely entirely on lemmatization\n",
    "- Hence we learn in NLTK about different stemmers i.e Porter Stemmer and Snowball Stemmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer.\n",
    "- Its one of common and effective stemming tool. This algorithm employs 5 phases of word reduction, each with its own set of mapping rules.\n",
    "- In first phase, simple suffix mapping  word reduces to stem and ES is removed. \n",
    "\n",
    "### Snowball Stemmer.\n",
    "- Its name of stemming language, this algorithm is more accurately called as the \"English Stemmer\" or \"Porter2 Stemmer\"\n",
    "- Its slight improvement over original Porter stemmer i.e both in logic and speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "words= ['run','runner','ran', 'runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----->run\n",
      "runner----->runner\n",
      "ran----->ran\n",
      "runs----->run\n",
      "easily----->easili\n",
      "fairly----->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '----->' + p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run----->run\n",
      "runner----->runner\n",
      "ran----->ran\n",
      "runs----->run\n",
      "easily----->easili\n",
      "fairly----->fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '----->' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous----->generous\n",
      "generation----->generat\n",
      "generously----->generous\n",
      "generate----->generat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '----->'+ s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lemmatization.\n",
    "- Beyond stemming, lemmatization looks in word reduction and considers a language's full vocabulary to apply a morphological analysis to words.\n",
    "- The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'.Further lemma of 'meeting' might be 'meet' or meeting depending on its use in a sentence.\n",
    "- This library is typically much more informative than simple stemming, which is why Spacy has opted to only have Lemmatization available instead of Stemming.\n",
    "- It looks at surrounding text to determine a given word's part of speech, it does not categorize phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,'\\t', token.pos_,'\\t', token.lemma,'\\t', token.lemma_)\n",
    "# '\\t' is for next tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  The number above points to s specific lemma inside this 'en_core_web_sm' language library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to display lemmas.\n",
    "- Since the display above is staggared and hard to read, using function we can display the information we require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}}{token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089    -PRON-\n",
      "saw          VERB   11925638236994514241  see\n",
      "eighteen     NUM    9609336664675087640   eighteen\n",
      "mice         NOUN   1384165645700560590   mouse\n",
      "today        NOUN   11042482332948150395  today\n",
      "!            PUNCT  17494803046312582752  !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>From above we can notice that lemma of 'saw' is 'see', 'mice' is 'mouse' and yet 'eighteen' is to its own number *not* an expanded form of 'eight'.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089    -PRON-\n",
      "am           AUX    10382539506755952630  be\n",
      "meeting      VERB   6880656908171229526   meet\n",
      "him          PRON   561228191312463089    -PRON-\n",
      "tomorrow     NOUN   3573583789758258062   tomorrow\n",
      "at           ADP    11667289587015813222  at\n",
      "the          DET    7425985699627899538   the\n",
      "meeting      NOUN   14798207169164081740  meeting\n",
      ".            PUNCT  12646065887601541794  .\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =green> Here the lemma of 'meeting' is determined by its Part of Speech tag. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stop Words.\n",
    "-  Words like \"a\" and \"the\" appear so frequently that they don't require tagging as thoroughly as nouns, verbs and modifiers.\n",
    "- We can call these stop words and they can be filtered from the text to be processed.\n",
    "-  SpaCy library holds a built-in list of some 305 English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading English Core Web Small language.\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'using', 'becomes', 'anywhere', 'together', 'anything', 'never', 'themselves', 'last', 'elsewhere', 'meanwhile', 'his', 'hers', 'various', 'fifty', 'whole', 'still', '’d', 'their', 'amount', 'beyond', 'had', '’m', 'nowhere', 're', 'and', 'hence', 'someone', 'all', 'former', 'neither', 'otherwise', 'well', 'done', 'make', 'via', 'other', '‘s', 'have', 'besides', 'do', 'already', 'does', 'between', 'nothing', 'show', 'beside', 'across', 'am', 'there', '’s', 'afterwards', 'please', 'next', 'we', 'being', 'both', 'full', 'yet', 'enough', 'others', 'onto', 'everything', 'formerly', 'moreover', 'ours', 'seem', 'unless', 'yours', \"'ll\", \"'ve\", 'else', 'myself', 'of', 'ten', 'up', 'least', 'i', 'keep', 'say', 'see', 'thru', 'only', '‘d', 'any', 'bottom', 'go', 'whither', 'would', 'beforehand', 'front', 'may', 'per', 'she', 'the', 'within', 'will', 'before', 'perhaps', 'did', 'he', 'thence', 'without', 'become', 'whence', 'nine', 'quite', 'throughout', 'by', 'eleven', \"n't\", 'also', 'less', 'somehow', 'until', 'latter', '‘m', '’ll', 'while', 'though', 'out', 'amongst', 'somewhere', 'thereby', 'whereafter', 'below', 'be', 'sometimes', 'such', 'due', 'seeming', 'six', 'another', 'third', 'fifteen', 'twenty', 'whether', 'just', 'over', 'whereas', 'ca', 'always', 'around', 'mine', 'whatever', 'for', 'our', 'however', 'these', 'during', 'ever', 'more', 'much', 'upon', 'really', 'cannot', 'twelve', 'n’t', 'top', 'hereupon', 'hundred', 'down', 'yourselves', 'whose', 'is', 'four', 'a', 'herein', 'what', 'those', 'so', 'latterly', 'after', \"'d\", 'might', 'move', 'himself', 'at', 'nobody', 'to', 'itself', 'with', 'same', 'how', 'along', 'part', 'are', 'that', 'almost', 'noone', 'very', 'not', 'many', 'this', 'whoever', 'among', 'most', 'an', 'it', 'none', 'forty', 'has', 'now', 'although', 'toward', 'why', 'us', 'its', 'where', 'several', 'seemed', 'but', 'they', 'one', 'wherever', 'into', 'from', 'some', 'hereby', 'about', 'each', 'can', 'or', 'two', 'wherein', 'your', 'few', 'was', 'became', 'something', 'herself', 'then', 'here', 'whereupon', 'through', 'nor', 'because', 'towards', '’re', 'even', 'them', 'everywhere', '‘re', 'either', 'too', 'which', 'name', 'her', 'seems', 'were', 'whenever', 'me', 'hereafter', \"'re\", 'take', 'put', 'eight', 'anyhow', 'as', 'on', 'serious', 'if', 'could', 'everyone', \"'m\", 'been', 'every', '’ve', 'should', 'doing', 'nevertheless', 'him', 'must', 'five', 'against', 'further', 'no', 'again', 'namely', 'once', 'rather', 'own', 'regarding', 'therein', 'thus', 'therefore', 'n‘t', 'when', 'above', 'indeed', 'side', \"'s\", 'thereafter', 'three', 'than', 'behind', 'sometime', 'used', 'give', 'in', 'sixty', 'ourselves', 'anyway', 'yourself', '‘ll', 'whereby', '‘ve', 'empty', 'thereupon', 'call', 'off', 'made', 'since', 'anyone', 'becoming', 'get', 'first', 'alone', 'back', 'mostly', 'who', 'under', 'whom', 'except', 'you', 'often', 'my'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check if a word is a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['ahmed'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'btw' is common short hand for \" by the way\".\n",
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= green > From above beyond is removed </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vocabulary and Matching.\n",
    "-  In previous conceptsd we have seen how a body is divided into tokens and how thse individual tokens are parsed and tagged with parts of speech, dependencies and lemmas.\n",
    "- In this section we'll **identify and label specific pharases that matches patterns** we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule -Based Matching.\n",
    "- SpaCy offers a rule-matching tool called **Matcher** which allows to build a library of token patterns, then match those patterns against Doc object to return a list of found matches.\n",
    "- We can match on any part of the token including text and annotations and can add multiple patterns to the same matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the patterns which are lists of dictionaries based of keywords. \n",
    "# SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "# Solar-power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}] # IS_PUNCT means is there punctuation in between.\n",
    "# Solar power\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pattern1` looks for the single token whose lowercase text ends 'solarpower'\n",
    "- `pattern2` looks for two adjacent tokens that read 'solar' and 'power' in that order\n",
    "- `pattern3` looks for the three adjacent tokens, with a middle token that can be any puntuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches=matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matcher`  returns a list of tuples. Each tuple contains an ID for thr match, with start & end token that maps to the span `doc[start:end]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # gives string representation\n",
    "    span = doc[start:end]                   # gives the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Remove the Pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Patterns.\n",
    "# solarpower, SolarPower \n",
    "pattern1= [{'LOWER':'solarpower'}]\n",
    "\n",
    "# solar.power\n",
    "patter2 = [{'LOWER':'solar'},{'IS_PUNCT':True, 'OP':'*'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This found both two-word patterns, with and without the hyphen!\n",
    "\n",
    "The following quantifiers can be passed to the `'OP'` key:\n",
    "<table><tr><th>OP</th><th>Description</th></tr>\n",
    "\n",
    "<tr ><td><span >\\!</span></td><td>Negate the pattern, by requiring it to match exactly 0 times</td></tr>\n",
    "<tr ><td><span >?</span></td><td>Make the pattern optional, by allowing it to match 0 or 1 times</td></tr>\n",
    "<tr ><td><span >\\+</span></td><td>Require the pattern to match 1 or more times</td></tr>\n",
    "<tr ><td><span >\\*</span></td><td>Allow the pattern to match zero or more times</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', None,pattern1,pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(u\"Solar----power is solarpower hey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 2, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Matcher\n",
    "- In order to create a document object from a list of phrases and pass into the matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference file.\n",
    "with open('reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAGANOMICS\n",
      "https://en.wikipedia.org/wiki/Reaganomics\n",
      "\n",
      "Reaganomics (a portmanteau of [Ronald] Reagan and economics attributed to Paul Harvey)[1] refers to the economic policies promoted by U.S. President Ronald Reagan during the 1980s. These policies are commonly associated with supply-side economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "The four pillars of Reagan's economic policy were to reduce the growth of government spending, reduce the federal income tax and capital gains tax, reduce government regulation, and tighten the money supply in order to reduce inflation.[2]\n",
      "\n",
      "The results of Reaganomics are still debated. Supporters point to the end of stagflation, stronger GDP growth, and an entrepreneur revolution in the decades that followed.[3][4] Critics point to the widening income gap, an atmosphere of greed, and the national debt tripling in eight years which ultimately reversed the post-World War II trend of a shrinking national debt as percentage of GDP.[5][6]\n",
      "\n",
      "HISTORICAL CONTEXT\n",
      "\n",
      "Prior to the Reagan administration, the United States economy experienced a decade of high unemployment and persistently high inflation (known as stagflation). Attacks on Keynesian economic orthodoxy as well as empirical economic models such as the Phillips Curve grew. Political pressure favored stimulus resulting in an expansion of the money supply. President Richard Nixon's wage and price controls were phased out.[7] The federal oil reserves were created to ease any future short term shocks. President Jimmy Carter had begun phasing out price controls on petroleum while he created the Department of Energy. Much of the credit for the resolution of the stagflation is given to two causes: a three-year contraction of the money supply by the Federal Reserve Board under Paul Volcker, initiated in the last year of Carter's presidency, and long-term easing of supply and pricing in oil during the 1980s oil glut.[citation needed]\n",
      "\n",
      "In stating that his intention was to lower taxes, Reagan's approach was a departure from his immediate predecessors. Reagan enacted lower marginal tax rates as well as simplified income tax codes and continued deregulation. During Reagan's eight year presidency, the annual deficits averaged 4.0% of GDP, compared to a 2.2% average during the preceding eight years.[8] The real (inflation adjusted) average rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan.[9][10] GDP per employed person increased at an average 1.5% rate during the Reagan administration, compared to an average 0.6% during the preceding eight years.[11] Private sector productivity growth, measured as real output per hour of all persons, increased at an average rate of 1.9% during Reagan's eight years, compared to an average 1.3% during the preceding eight years.[12] Federal net outlays as a percent of GDP averaged 21.4% under Reagan, compared to 19.1% during the preceding eight years.[13]\n",
      "\n",
      "During the Nixon and Ford Administrations, before Reagan's election, a combined supply and demand side policy was considered unconventional by the moderate wing of the Republican Party. While running against Reagan for the Presidential nomination in 1980, George H. W. Bush had derided Reaganomics as \"voodoo economics\".[14] Similarly, in 1976, Gerald Ford had severely criticized Reagan's proposal to turn back a large part of the Federal budget to the states.\n",
      "\n",
      "JUSTIFICATIONS\n",
      "\n",
      "In his 1980 campaign speeches, Reagan presented his economic proposals as a return to the free enterprise principles, free market economy that had been in favor before the Great Depression and FDR's New Deal policies. At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-stimulus economics. This movement produced some of the strongest supporters for Reagan's policies during his term in office.\n",
      "\n",
      "The contention of the proponents, that the tax rate cuts would more than cover any increases in federal debt, was influenced by a theoretical taxation model based on the elasticity of tax rates, known as the Laffer curve. Arthur Laffer's model predicts that excessive tax rates actually reduce potential tax revenues, by lowering the incentive to produce; the model also predicts that insufficient tax rates (rates below the optimum level for a given economy) lead directly to a reduction in tax revenues.\n",
      "\n",
      "POLICIES\n",
      "\n",
      "Reagan lifted remaining domestic petroleum price and allocation controls on January 28, 1981,[15] and lowered the oil windfall profits tax in August 1981. He ended the oil windfall profits tax in 1988.[16] During the first year of Reagan's presidency, federal income tax rates were lowered significantly with the signing of the Economic Recovery Tax Act of 1981,[17] which lowered the top marginal tax bracket from 70% to 50% and the lowest bracket from 14% to 11%. This act slashed estate taxes and trimmed taxes paid by business corporations by $150 billion over a five-year period. In 1982 Reagan agreed to a rollback of corporate tax cuts and a smaller rollback of individual income tax cuts. The 1982 tax increase undid a third of the initial tax cut. In 1983 Reagan instituted a payroll tax increase on Social Security and Medicare hospital insurance.[18] In 1984 another bill was introduced that closed tax loopholes. According to tax historian Joseph Thorndike, the bills of 1982 and 1984 \"constituted the biggest tax increase ever enacted during peacetime\".[19]\n",
      "\n",
      "With the Tax Reform Act of 1986, Reagan and Congress sought to simplify the tax system by eliminating many deductions, reducing the highest marginal rates, and reducing the number of tax brackets.[20][21][22][23] In 1983, Democrats Bill Bradley and Dick Gephardt had offered a proposal; in 1984 Reagan had the Treasury Department produce its own plan. The 1986 act aimed to be revenue-neutral: while it reduced the top marginal rate, it also cleaned up the tax base by removing certain tax write-offs, preferences, and exceptions, thus raising the effective tax on activities previously specially favored by the code. Ultimately, the combination of the decrease in deductions and decrease in rates raised revenue equal to about 4% of existing tax revenue.[24]\n",
      "\n",
      "Federal revenue share of GDP fell from 19.6% in fiscal 1981 to 17.3% in 1984, before rising back to 18.4% by fiscal year 1989. Personal income tax revenues fell during this period relative to GDP, while payroll tax revenues rose relative to GDP.[25] Reagan's 1981 cut in the top regular tax rate on unearned income reduced the maximum capital gains rate to only 20% – its lowest level since the Hoover administration.[26] The 1986 act set tax rates on capital gains at the same level as the rates on ordinary income like salaries and wages, with both topping out at 28%.[27]\n",
      "\n",
      "Reagan significantly increased public expenditures, primarily the Department of Defense, which rose (in constant 2000 dollars) from $267.1 billion in 1980 (4.9% of GDP and 22.7% of public expenditure) to $393.1 billion in 1988 (5.8% of GDP and 27.3% of public expenditure); most of those years military spending was about 6% of GDP, exceeding this number in 4 different years. All these numbers had not been seen since the end of U.S. involvement in the Vietnam War in 1973.[28] In 1981, Reagan significantly reduced the maximum tax rate, which affected the highest income earners, and lowered the top marginal tax rate from 70% to 50%; in 1986 he further reduced the rate to 28%.[29] The federal deficit under Reagan peaked at 6% of GDP in 1983, falling to 3.2% of GDP in 1987[30] and to 3.1% of GDP in his final budget.[31] The inflation-adjusted rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan. This was the slowest rate of growth in inflation adjusted spending since Eisenhower. However, federal deficit as percent of GDP was up throughout the Reagan presidency from 2.7% at the end of (and throughout) the Carter administration.[9][31][32] As a short-run strategy to reduce inflation and lower nominal interest rates, the U.S. borrowed both domestically and abroad to cover the Federal budget deficits, raising the national debt from $997 billion to $2.85 trillion.[33] This led to the U.S. moving from the world's largest international creditor to the world's largest debtor nation.[5] Reagan described the new debt as the \"greatest disappointment\" of his presidency.[34]\n",
      "\n",
      "According to William A. Niskanen, one of the architects of Reaganomics, \"Reagan delivered on each of his four major policy objectives, although not to the extent that he and his supporters had hoped\", and notes that the most substantial change was in the tax code, where the top marginal individual income tax rate fell from 70.1% to 28.4%, and there was a \"major reversal in the tax treatment of business income\", with effect of \"reducing the tax bias among types of investment but increasing the average effective tax rate on new investment\". Roger Porter, another architect of the program, acknowledges that the program was weakened by the many hands that changed the President's calculus, such as Congress.[2][35] President Reagan raised taxes eleven times over the course of his presidency, but the overall tax burden went down during his presidency.[36][37] According to Paul Krugman, \"Over all, the 1982 tax increase undid about a third of the 1981 cut; as a share of GDP, the increase was substantially larger than Mr. Clinton's 1993 tax increase.\"[18] According to historian and domestic policy adviser Bruce Bartlett, Reagan's tax increases over the course of his presidency took back half of the 1981 tax cut. Though since the Reagan tax reductions, top marginal tax rates have remained lower than at any point in US history since 1931, when the top marginal rate was raised from 25% to 63%.[38]\n",
      "\n",
      "RESULTS\n",
      "\n",
      "Overview\n",
      "\n",
      "Spending during the years Reagan budgeted (FY 1982–89) averaged 21.6% GDP, roughly tied with President Obama for the highest among any recent President. Each faced a severe recession early in their administration. In addition, the public debt rose from 26% GDP in 1980 to 41% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2.052 trillion in 1988, a roughly three-fold increase.[25]:143 The unemployment rate rose from 7% in 1980 to 11% in 1982, then declined to 5% in 1988. The inflation rate declined from 10% in 1980 to 4% in 1988.[2]\n",
      "\n",
      "Some economists have stated that Reagan's policies were an important part of bringing about the third longest peacetime economic expansion in U.S. history.[39][40] During the Reagan administration, real GDP growth averaged 3.5%, compared to 2.9% during the preceding eight years.[41] The annual average unemployment rate declined by 1.7 percentage points, from 7.2% in 1980 to 5.5% in 1988, after it had increased by 1.6 percentage points over the preceding eight years.[42][43] Nonfarm employment increased by 16.1 million during Reagan's presidency, compared to 15.4 million during the preceding eight years,[44] while manufacturing employment declined by 582,000 after rising 363,000 during the preceding eight years.[45] Reagan's administration is the only one not to have raised the minimum wage.[46] The inflation rate, 13.5% in 1980, fell to 4.1% in 1988, due to the Federal Reserve increasing interest rates (prime rate peaking at 20.5% in August 1981[47]).[48] The latter contributed to a recession from July 1981 to November 1982 during which unemployment rose to 9.7% and GDP fell by 1.9%. Additionally, income growth slowed for middle- and lower-class (2.4% to 1.8%) and rose for the upper-class (2.2% to 4.83%).[49]\n",
      "\n",
      "The misery index, defined as the inflation rate added to the unemployment rate, shrank from 19.33 when he began his administration to 9.72 when he left, the greatest improvement record for a President since Harry S. Truman left office.[50] In terms of American households, the percentage of total households making less than $10,000 a year (in real 2007 dollars) shrank from 8.8% in 1980 to 8.3% in 1988 while the percentage of households making over $75,000 went from 20.2% to 25.7% during that period, both signs of progress.[51]\n",
      "\n",
      "Employment and wages\n",
      "\n",
      "The job growth (measured for non-farm payrolls) under the Reagan administration averaged 168,000 per month, versus 216,000 for Carter, 55,000 for H.W. Bush, and 239,000 for Clinton. Measuring the number of jobs created per month is limited for longer time periods as the population grows. To address this, we can measure annual job growth percentages, comparing the beginning and ending number of jobs during their time in office to determine an annual growth rate. Jobs grew by 2.0% annually under Reagan, versus 3.1% under Carter, 0.6% under H.W. Bush, and 2.4% under Clinton.[52]\n",
      "\n",
      "The unemployment rate averaged 7.5% under Reagan, compared to an average 6.6% during the preceding eight years. Declining steadily after December 1982, the rate was 5.4% the month Reagan left office.[53]\n",
      "\n",
      "The average real hourly wage for production and nonsupervisory workers continued the decline that had begun in 1973, albeit at a slower rate, and remained below the pre-Reagan level in every Reagan year.[54]\n",
      "\n",
      "The labor force participation rate increased by 2.6 percentage points during Reagan's eight years, compared to 3.9 percentage points during the preceding eight years.[55]\n",
      "\n",
      "Growth rates\n",
      "\n",
      "Following the 1981 recession, the unemployment rate had averaged slightly higher (6.75% vs. 6.35%), productivity growth lower (1.38% vs. 1.92%), and private investment as a percentage of GDP slightly less (16.08% vs. 16.86%).[citation needed] In the 1980's, industrial productivity growth in the United States matched that of its trading partners after trailing them in the 1970's. By 1990, manufacturing's share of GNP exceeded the post-World War II low hit in 1982 and matched \"the level of output achieved in the 1960's when American factories hummed at a feverish clip\".[56]\n",
      "\n",
      "GDP growth\n",
      "\n",
      "Real GDP grew over one-third during Reagan’s presidency, an over $2 trillion increase. The compound annual growth rate of GDP was 3.6% during Reagan's eight years, compared to 2.7% during the preceding eight years.[57] Real GDP per capita grew 2.6% under Reagan, compared to 1.9% average growth during the preceding eight years.[58]\n",
      "\n",
      "Income and wealth\n",
      "In nominal terms, median household income grew at a compound annual growth rate (CAGR) of 5.5% during the Reagan presidency, compared to 8.5% during the preceding five years (pre-1975 data are unavailable).[59] Real median family income grew by $4,492 during the Reagan period, compared to a $1,270 increase during the preceding eight years.[60] After declining from 1974 through 1980, real mean personal income rose $4,708 by 1988.[61] Nominal household net worth increased by a CAGR of 8.4%, compared to 9.3% during the preceding eight years.[62]\n",
      "\n",
      "Poverty level\n",
      "\n",
      "The percentage of the total population below the poverty level increased from 13.0% in 1980 to 15.2% in 1983, then declined back to 13.0% in 1988.[64] During Reagan's first term, critics noted homelessness as a visible problem in U.S. urban centers.[65] In the closing weeks of his presidency, Reagan told David Brinkley that the homeless \"make it their own choice for staying out there,\" noting his belief that there \"are shelters in virtually every city, and shelters here, and those people still prefer out there on the grates or the lawn to going into one of those shelters\". He also stated that \"a large proportion\" of them are \"mentally impaired.\" A result (he believed) of ACLU (and similar organizations) lawsuits against institutions.[66] His policies became widely known as \"trickle-down economics\", due to the significant cuts in the upper tax brackets, as that extra money for the wealthy could trickle along to low-income groups.[67]\n",
      "\n",
      "Federal income tax and payroll tax levels\n",
      "\n",
      "During the Reagan administration, fiscal year federal receipts grew from $599 billion to $991 billion (an increase of 65%) while fiscal year federal outlays grew from $678 billion to $1144 billion (an increase of 69%).[68][69] According to a 1996 report of the Joint Economic Committee of the United States Congress, during Reagan's two terms, and through 1993, the top 10% of taxpayers paid an increased share of income taxes (not including payroll taxes) to the Federal government, while the lowest 50% of taxpayers paid a reduced share of income tax revenue.[70] Personal income tax revenues declined from 9.4% GDP in 1981 to 8.3% GDP in 1989, while payroll tax revenues increased from 6.0% GDP to 6.7% GDP during the same period.[25]\n",
      "\n",
      "Tax receipts\n",
      "\n",
      "According to a 2003 Treasury study, the tax cuts in the Economic Recovery Tax Act of 1981 resulted in a significant decline in revenue relative to a baseline without the cuts, approximately $111 billion (in 1992 dollars) on average during the first four years after implementation or nearly 3% GDP annually.[71][72] Other tax bills had neutral or, in the case of the Tax Equity and Fiscal Responsibility Act of 1982, a (~+1% of GDP) increase in revenue as a share of GDP. It should be noted, however, that the study did not examine the longer-term impact of Reagan tax policy, including sunset clauses and \"the long-run, fully-phased-in effect of the tax bills\".[72] The fact that tax receipts as a percentage of GDP fell following the Economic Recovery Tax Act of 1981 shows a decrease in tax burden as share of GDP and a commensurate increase in the deficit, as spending did not fall relative to GDP. Total federal tax receipts increased in every Reagan year except 1982, at an annual average rate of 6.2% compared to 10.8% during the preceding eight years.[73]\n",
      "\n",
      "The effect of Reagan's 1981 tax cuts (reduced revenue relative to a baseline without the cuts) were at least partially offset by phased in Social Security payroll tax increases that had been enacted by President Jimmy Carter and the 95th Congress in 1977, and further increases by Reagan in 1983[74] and following years, also to counter the uses of tax shelters.[75] An accounting indicated nominal tax receipts increased from $599 billion in 1981 to $1.032 trillion in 1990, an increase of 72% in current dollars. In 2005 dollars, the tax receipts in 1990 were $1.5 trillion, an increase of 20% above inflation.[76]\n",
      "\n",
      "Debt and government expenditures\n",
      "Reagan was inaugurated in January 1981, so the first fiscal year (FY) he budgeted was 1982 and the final year was 1989.\n",
      "\n",
      "During Reagan's presidency, the federal debt held by the public nearly tripled in nominal terms, from $738 billion to $2.1 trillion.[77] This led to the U.S. moving from the world's largest international creditor to the world's largest debtor nation.[5] Reagan described the new debt as the \"greatest disappointment\" of his presidency.[34]\n",
      "The federal deficit as percentage of GDP rose from 2.5% of GDP in fiscal year 1981 to a peak of 5.7% of GDP in 1983, then fell to 2.7% GDP in 1989.[78]\n",
      "Total federal outlays averaged of 21.8% of GDP from 1981–88, versus the 1974–1980 average of 20.1% of GDP. This was the highest of any President from Carter through Obama.[79]\n",
      "Total federal revenues averaged 17.7% of GDP from 1981–88, versus the 1974–80 average of 17.6% of GDP.[80]\n",
      "Federal individual income tax revenues fell from 8.7% of GDP in 1980 to a trough of 7.5% of GDP in 1984, then rose to 7.8% of GDP in 1988.[81]\n",
      "Business and market performance\n",
      "Nominal after-tax corporate profits grew at a compound annual growth rate of 3.0% during Reagan's eight years, compared to 13.0% during the preceding eight years.[82] The S&P 500 Index increased 113.3% during the 2024 trading days under Reagan, compared to 10.4% during the preceding 2024 trading days.[83] The business sector share of GDP, measured as gross private domestic investment, declined by 0.7 percentage points under Reagan, after increasing 0.7 percentage points during the preceding eight years.[84]\n",
      "\n",
      "Size of federal government\n",
      "The federal government's share of GDP increased 0.2 percentage points under Reagan, while it decreased 1.5 percentage points during the preceding eight years.[85] The number of federal civilian employees increased 4.2% during Reagan's eight years, compared to 6.5% during the preceding eight years.[86]\n",
      "\n",
      "As a candidate, Reagan asserted he would shrink government by abolishing the Cabinet-level departments of energy and education. He abolished neither, but elevated veterans affairs from independent agency status to Cabinet-level department status.[87][88]\n",
      "\n",
      "Income distribution\n",
      "Further information: Income inequality in the United States\n",
      "Continuing a trend that began in the 1970s, income inequality grew and accelerated in the 1980s. The Economist wrote in 2006: \"After the 1973 oil shocks, productivity growth suddenly slowed. A few years later, at the start of the 1980s, the gap between rich and poor began to widen.\"[89] According to the CBO:\n",
      "\n",
      "The top 1% of income earners' share of income before transfers and taxes rose from 9.0% in 1979 to a peak of 13.8% in 1986, before falling to 12.3% in 1989.\n",
      "The top 1% share of income earners' of income after transfers and taxes rose from 7.4% in 1979 to a peak of 12.8% in 1986, before falling to 11.0% in 1989.\n",
      "The bottom 90% had a lower share of the income in 1989 vs. 1979.[90]\n",
      "\n",
      "ANALYSIS\n",
      "\n",
      "According to a 1996 study[93] by the Cato Institute, a libertarian think tank, on 8 of the 10 key economic variables examined, the American economy performed better during the Reagan years than during the pre- and post-Reagan years. The study asserted that real median family income grew by $4,000 and during the eight Reagan years and experienced a loss of almost $1,500 in the post-Reagan years. Interest rates, inflation, and unemployment fell faster under Reagan than they did immediately before or after his presidency. The only economic variable that was lower during period than in both the pre- and post-Reagan years was the savings rate, which fell rapidly in the 1980s. The productivity rate was higher in the pre-Reagan years but lower in the post-Reagan years.[93] The Cato study was dismissive of any positive effects of tightening, and subsequent loosening, of Federal Reserve monetary policy under \"inflation hawk\" Paul Volcker, whom President Carter had appointed in 1979 to halt the persistent inflation of the 1970s.\n",
      "\n",
      "Economic analyst Stephen Moore stated in the Cato analysis, \"No act in the last quarter century had a more profound impact on the U.S. economy of the eighties and nineties than the Reagan tax cut of 1981.\" He argued that Reagan's tax cuts, combined with an emphasis on federal monetary policy, deregulation, and expansion of free trade created a sustained economic expansion, the greatest American sustained wave of prosperity ever. He also claims that the American economy grew by more than a third in size, producing a $15 trillion increase in American wealth. Consumer and investor confidence soared. Cutting federal income taxes, cutting the U.S. government spending budget, cutting useless programs, scaling down the government work force, maintaining low interest rates, and keeping a watchful inflation hedge on the monetary supply was Ronald Reagan's formula for a successful economic turnaround.[93]\n",
      "\n",
      "Milton Friedman stated, \"Reaganomics had four simple principles: Lower marginal tax rates, less regulation, restrained government spending, noninflationary monetary policy. Though Reagan did not achieve all of his goals, he made good progress.\"[94]\n",
      "\n",
      "The Tax Reform Act of 1986 and its impact on the alternative minimum tax (AMT) reduced nominal rates on the wealthy and eliminated tax deductions, while raising tax rates on lower-income individuals.[94][95][96][97] The across the board tax system reduced marginal rates and further reduced bracket creep from inflation. The highest income earners (with incomes exceeding $1,000,000) received a tax break, restoring a flatter tax system.[98] In 2006, the IRS's National Taxpayer Advocate's report characterized the effective rise in the AMT for individuals as a problem with the tax code.[99] Through 2007, the revised AMT had brought in more tax revenue than the former tax code, which has made it difficult for Congress to reform.[98][100]\n",
      "\n",
      "Economist Paul Krugman argued the economic expansion during the Reagan administration was primarily the result of the business cycle and the monetary policy by Paul Volcker.[101] Krugman argues that there was nothing unusual about the economy under Reagan because unemployment was reducing from a high peak and that it is consistent with Keynesian economics for the economy to grow as employment increases if inflation remains low.[102]\n",
      "\n",
      "The CBO Historical Tables indicate that federal spending during Reagan's two terms (FY 1981–88) averaged 22.4% GDP, well above the 20.6% GDP average from 1971 to 2009. In addition, the public debt rose from 26.1% GDP in 1980 to 41.0% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2,052 billion in 1988, a three-fold increase.[25] Krugman argued in June 2012 that Reagan's policies were consistent with Keynesian stimulus theories, pointing to the significant increase in per-capita spending under Reagan.[103]\n",
      "\n",
      "William Niskanen noted that during the Reagan years, privately held federal debt increased from 22% to 38% of GDP, despite a long peacetime expansion. Second, the savings and loan problem led to an additional debt of about $125 billion. Third, greater enforcement of U.S. trade laws increased the share of U.S. imports subjected to trade restrictions from 12% in 1980 to 23% in 1988.[2]\n",
      "\n",
      "Economists Raghuram Rajan and Luigi Zingales pointed out that many deregulation efforts had either taken place or had begun before Reagan (note the deregulation of airlines and trucking under Carter, and the beginning of deregulatory reform in railroads, telephones, natural gas, and banking). They stated, \"The move toward markets preceded the leader [Reagan] who is seen as one of their saviors.\"[104] Economists Paul Joskow and Roger Noll made a similar contention.[105]\n",
      "\n",
      "Economist William A. Niskanen, a member of Reagan's Council of Economic Advisers wrote that deregulation had the \"lowest priority\" of the items on the Reagan agenda[2] given that Reagan \"failed to sustain the momentum for deregulation initiated in the 1970s\" and that he \"added more trade barriers than any administration since Hoover.\" By contrast, economist Milton Friedman has pointed to the number of pages added to the Federal Register each year as evidence of Reagan's anti-regulation presidency (the Register records the rules and regulations that federal agencies issue per year). The number of pages added to the Register each year declined sharply at the start of the Ronald Reagan presidency breaking a steady and sharp increase since 1960. The increase in the number of pages added per year resumed an upward, though less steep, trend after Reagan left office. In contrast, the number of pages being added each year increased under Ford, Carter, George H. W. Bush, Clinton, George W. Bush, and Obama.[106] The number of pages in Federal Register is however criticized as an extremely crude measure of regulatory activity, because it can be easily manipulated (e.g. font sizes have been changed to keep page count low).[107] The apparent contradiction between Niskanen's statements and Friedman's data may be resolved by seeing Niskanen as referring to statutory deregulation (laws passed by Congress) and Friedman to administrative deregulation (rules and regulations implemented by federal agencies). A 2016 study by the Congressional Research Service found that Reagan's average annual number of final federal regulatory rules published in the Federal Register was higher than during the Clinton, George W. Bush or Obama's administrations, even though the Reagan economy was considerably smaller than during those later presidents.[108] Another study by the QuantGov project of the libertarian Mercatus Center found that the Reagan administration added restrictive regulations — containing such terms as \"shall,\" \"prohibited\" or \"may not\" — at a faster average annual rate than did Clinton, Bush or Obama.[109]\n",
      "\n",
      "Greg Mankiw, a conservative Republican economist who served as chairman of the Council of Economic Advisors under President George W. Bush, wrote in 2007:\n",
      "\n",
      "I used the phrase \"charlatans and cranks\" in the first edition of my principles textbook to describe some of the economic advisers to Ronald Reagan, who told him that broad-based income tax cuts would have such large supply-side effects that the tax cuts would raise tax revenue. I did not find such a claim credible, based on the available evidence. I never have, and I still don't...My other work has remained consistent with this view. In a paper on dynamic scoring, written while I was working at the White House, Matthew Weinzierl and I estimated that a broad-based income tax cut (applying to both capital and labor income) would recoup only about a quarter of the lost revenue through supply-side growth effects. For a cut in capital income taxes, the feedback is larger — about 50 percent — but still well under 100 percent. A chapter on dynamic scoring in the 2004 Economic Report of the President says about the the [sic] same thing.[110]\n",
      "\n",
      "Glenn Hubbard, who preceded Mankiw as Bush's CEA chair, also disputed the assertion that tax cuts increase tax revenues, writing in his 2003 Economic Report of the President: \"Although the economy grows in response to tax reductions (because of higher consumption in the short run and improved incentives in the long run), it is unlikely to grow so much that lost tax revenue is completely recovered by the higher level of economic activity.\"[111]\n",
      "\n",
      "In 1986, Martin Feldstein — a self-described \"traditional supply sider\" who served as Reagan's chairman of the Council of Economic Advisors from 1982 to 1984 — characterized the \"new supply siders\" who emerged circa 1980:\n",
      "\n",
      "What distinguished the new supply siders from the traditional supply siders as the 1980s began was not the policies they advocated but the claims that they made for those policies...The \"new\" supply siders were much more extravagant in their claims. They projected rapid growth, dramatic increases in tax revenue, a sharp rise in saving, and a relatively painless reduction in inflation. The height of supply side hyperbole was the \"Laffer curve\" proposition that the tax cut would actually increase tax revenue because it would unleash an enormously depressed supply of effort. Another remarkable proposition was the claim that even if the tax cuts did lead to an increased budget deficit, that would not reduce the funds available for investment in plant and equipment because tax changes would raise the saving rate by enough to finance the increased deficit...Nevertheless, I have no doubt that the loose talk of the supply side extremists gave fundamentally good policies a bad name and led to quantitative mistakes that not only contributed to subsequent budget deficits but that also made it more difficult to modify policy when those deficits became apparent.[112]\n",
      "\n",
      "FOOTNOTES\n",
      "\n",
      "https://en.wikipedia.org/wiki/Reaganomics#Footnotes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for Phrases by creating a variable.\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each phrase into Document object.\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('EconMatcher', None, *phrase_patterns) # * selects all objects.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3680293220734633682, 41, 45),\n",
       " (3680293220734633682, 49, 53),\n",
       " (3680293220734633682, 54, 56),\n",
       " (3680293220734633682, 61, 65),\n",
       " (3680293220734633682, 673, 677),\n",
       " (3680293220734633682, 2987, 2991)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches = matcher(doc3)\n",
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 supply-side economics\n",
      "3680293220734633682 EconMatcher 49 53 trickle-down economics\n",
      "3680293220734633682 EconMatcher 54 56 voodoo economics\n",
      "3680293220734633682 EconMatcher 61 65 free-market economics\n",
      "3680293220734633682 EconMatcher 673 677 supply-side economics\n",
      "3680293220734633682 EconMatcher 2987 2991 trickle-down economics\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # gives string representation\n",
    "    span = doc3[start:end]                   # gives the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional information visit https://spacy.io/usage/linguistic-features#section-rule-based-matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
